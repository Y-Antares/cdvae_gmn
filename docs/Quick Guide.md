# Enhanced CDVAE Quick Start Guide
## å¿«é€Ÿå…¥é—¨æŒ‡å—

### ğŸš€ 5åˆ†é’Ÿå¿«é€Ÿå¼€å§‹

#### ç¬¬ä¸€æ­¥: ç¯å¢ƒå‡†å¤‡
```bash
# å…‹éš†é¡¹ç›®
git clone <your-repo-url>
cd cdvae

# å®‰è£…ä¾èµ–
conda create -n cdvae python=3.8
conda activate cdvae
pip install -r requirements.txt

# è®¾ç½®ç¯å¢ƒå˜é‡
export PROJECT_ROOT="/path/to/enhanced-cdvae"
export PYTHONPATH="${PROJECT_ROOT}:${PYTHONPATH}"
```

#### ç¬¬äºŒæ­¥: æ•°æ®å‡†å¤‡ (2åˆ†é’Ÿ)
```bash
# ä½¿ç”¨ç¤ºä¾‹æ•°æ®æˆ–å‡†å¤‡ä½ çš„æ•°æ®
# CSVæ ¼å¼: material_id, cif, formation_energy_per_atom, target_property

# å¿«é€Ÿå¤„ç†ç¤ºä¾‹æ•°æ®
python config_manager.py run small_test \
  --input examples/sample_data.csv \
  --output_dir data/quick_test \
  --train_size 1000

# æ£€æŸ¥ç»“æœ
ls data/quick_test/
# åº”è¯¥çœ‹åˆ°: train.csv, val.csv, test.csv, metadata.json
```

#### ç¬¬ä¸‰æ­¥: æ¨¡å‹è®­ç»ƒ (ä¸»è¦æ—¶é—´)
```bash
# å¿«é€Ÿè®­ç»ƒ (å°è§„æ¨¡æµ‹è¯•)
python train_enhanced_cdvae.py \
  --config conf/data/quick_test.yaml \
  --dataset quick_test \
  --gradnorm \
  --multi_obj_method weighted \
  --max_epochs 50 \
  --output_dir results/quick_test

# ç”Ÿäº§çº§è®­ç»ƒ (å®Œæ•´è®­ç»ƒ)
python train_enhanced_cdvae.py \
  --config conf/data/your_dataset.yaml \
  --dataset your_dataset \
  --gradnorm \
  --multi_obj_method tchebycheff \
  --max_epochs 300 \
  --output_dir results/production
```

#### ç¬¬å››æ­¥: è¯„ä¼°å’Œåˆ†æ (2åˆ†é’Ÿ)
```bash
# å¿«é€Ÿè¯„ä¼°
python enhanced_compute_metrics.py \
  --root_path results/quick_test \
  --methods weighted \
  --target_types combined

# å¯è§†åŒ–ç»“æœ
python visualize_pareto.py \
  --model_path results/quick_test \
  --methods weighted \
  --target_type combined \
  --save_data \
  --show_plot
```

---

### ğŸ“‹ å¸¸ç”¨å‘½ä»¤é€ŸæŸ¥

#### æ•°æ®é¢„å¤„ç†å‘½ä»¤
```bash
# åˆ—å‡ºé¢„å®šä¹‰é…ç½®
python config_manager.py list

# æŸ¥çœ‹ç‰¹å®šé…ç½®
python config_manager.py show perovskite_bandgap

# ä½¿ç”¨é…ç½®å¤„ç†æ•°æ®
python config_manager.py run [CONFIG_NAME] \
  --input [INPUT.csv] \
  --output_dir [OUTPUT_DIR] \
  --train_size [SIZE]
```

#### è®­ç»ƒå‘½ä»¤æ¨¡æ¿
```bash
python train_enhanced_cdvae.py \
  --config [CONFIG.yaml] \
  --dataset [DATASET_NAME] \
  [--gradnorm] \
  --multi_obj_method [weighted|tchebycheff|boundary] \
  --max_epochs [EPOCHS] \
  --output_dir [OUTPUT_DIR]
```

#### è¯„ä¼°å‘½ä»¤æ¨¡æ¿
```bash
# æ ‡å‡†è¯„ä¼°
python evaluate.py \
  --model_path [MODEL_PATH] \
  --tasks recon gen opt \
  --target_type combined \
  --optimization_method [METHOD]

# å¢å¼ºè¯„ä¼°
python enhanced_compute_metrics.py \
  --root_path [MODEL_PATH] \
  --methods [METHOD1] [METHOD2] \
  --target_types combined
```

---

### ğŸ¯ å…¸å‹ä½¿ç”¨åœºæ™¯

#### åœºæ™¯1: é’™é’›çŸ¿å¤ªé˜³èƒ½ææ–™
```bash
# 1. æ•°æ®å‡†å¤‡
python config_manager.py run perovskite_bandgap \
  --input data/perovskite_solar.csv \
  --output_dir data/perov_processed \
  --train_size 12000

# 2. è®­ç»ƒæ¨¡å‹
python train_enhanced_cdvae.py \
  --config conf/data/perov_processed.yaml \
  --dataset perovskite \
  --gradnorm \
  --multi_obj_method tchebycheff \
  --max_epochs 300 \
  --output_dir results/perov_solar

# 3. åˆ†æç»“æœ
python enhanced_compute_metrics.py \
  --root_path results/perov_solar \
  --methods tchebycheff \
  --target_types combined
```

#### åœºæ™¯2: é«˜å¼ºåº¦ææ–™å‘ç°
```bash
# 1. æ•°æ®å‡†å¤‡
python config_manager.py run carbon_elastic \
  --input data/carbon_materials.csv \
  --output_dir data/carbon_processed \
  --train_size 8000

# 2. è®­ç»ƒæ¨¡å‹
python train_enhanced_cdvae.py \
  --config conf/data/carbon_processed.yaml \
  --dataset carbon \
  --gradnorm \
  --multi_obj_method boundary \
  --max_epochs 350 \
  --output_dir results/carbon_strength

# 3. å¯è§†åŒ–ç»“æœ
python visualize_pareto.py \
  --model_path results/carbon_strength \
  --methods boundary \
  --target_type combined \
  --save_data
```

#### åœºæ™¯3: æ–¹æ³•å¯¹æ¯”ç ”ç©¶
```bash
# æ‰¹é‡è®­ç»ƒä¸åŒæ–¹æ³•
methods=("weighted" "tchebycheff" "boundary")
for method in "${methods[@]}"; do
  for gradnorm in "" "--gradnorm"; do
    suffix=$([ -n "$gradnorm" ] && echo "_gradnorm" || echo "_fixed")
    
    python train_enhanced_cdvae.py \
      --config conf/data/dataset.yaml \
      --dataset comparison \
      $gradnorm \
      --multi_obj_method $method \
      --max_epochs 300 \
      --output_dir results/${method}${suffix}
  done
done

# ç»¼åˆåˆ†æ
python scripts/compare_all_methods.py \
  --result_dirs results/*/ \
  --output_dir comparison_analysis
```

---

### âš™ï¸ é…ç½®æ–‡ä»¶å¿«é€Ÿè®¾ç½®

#### æ•°æ®é…ç½®æ¨¡æ¿ (conf/data/your_dataset.yaml)
```yaml
root_path: ${oc.env:PROJECT_ROOT}/data/your_processed_data
prop: target_property
target_property: target_property
num_targets: 2
niggli: true
primitive: false
graph_method: crystalnn
lattice_scale_method: scale_length
preprocess_workers: 16
readout: mean
max_atoms: 200
otf_graph: false
eval_model_name: your_dataset

# å¤šç›®æ ‡é…ç½®
multi_target: true
energy_weight: 0.6
property_weights: [0.6, 0.4]
optimization_method: "tchebycheff"
optimization_direction: [min, max]

train_max_epochs: 300
early_stopping_patience: 50
teacher_forcing_max_epoch: 150

datamodule:
  _target_: cdvae.pl_data.datamodule.CrystDataModule
  datasets:
    train:
      _target_: cdvae.pl_data.dataset.CrystDataset
      name: Your dataset train
      path: ${data.root_path}/train.csv
      prop: ${data.prop}
      # ... å…¶ä»–é…ç½®

  num_workers:
    train: 8
    val: 4
    test: 4

  batch_size:
    train: 256
    val: 128
    test: 128
```

#### æ¨¡å‹é…ç½®æ¨¡æ¿ (conf/model/enhanced_cdvae.yaml)
```yaml
_target_: enhanced_cdvae.EnhancedCDVAE
hidden_dim: 256
latent_dim: 256
fc_num_layers: 1
max_atoms: ${data.max_atoms}

# åŸºç¡€æŸå¤±æƒé‡
cost_natom: 1.0
cost_coord: 10.0
cost_type: 1.0
cost_lattice: 10.0
cost_composition: 1.0
cost_edge: 10.0
cost_property: 1.0
beta: 0.01

# å¤šç›®æ ‡ä¼˜åŒ–é…ç½®
multi_objective:
  method: "tchebycheff"
  weights: [0.6, 0.4]
  direction: [min, max]
  boundary_theta: 5.0
  init_ideal_points: [999.0, 999.0]

# GradNormé…ç½®
gradnorm:
  enable: true
  alpha: 1.5
  lr: 0.025

# å…¶ä»–è®­ç»ƒå‚æ•°
teacher_forcing_lattice: true
teacher_forcing_max_epoch: ${data.teacher_forcing_max_epoch}
predict_property: true

defaults:
  - encoder: dimenet
  - decoder: gemnet
```

---

### ğŸ”§ æ•…éšœæ’é™¤

#### å¸¸è§é—®é¢˜åŠè§£å†³æ–¹æ¡ˆ

**é—®é¢˜1: å†…å­˜ä¸è¶³**
```bash
# è§£å†³æ–¹æ¡ˆ: å‡å°‘æ‰¹å¤§å°
# åœ¨é…ç½®æ–‡ä»¶ä¸­ä¿®æ”¹:
batch_size:
  train: 128  # ä»256å‡å°‘åˆ°128
  val: 64
  test: 64
```

**é—®é¢˜2: è®­ç»ƒä¸æ”¶æ•›**
```bash
# è§£å†³æ–¹æ¡ˆ: è°ƒæ•´å­¦ä¹ ç‡å’ŒGradNormå‚æ•°
# åœ¨é…ç½®æ–‡ä»¶ä¸­ä¿®æ”¹:
gradnorm:
  alpha: 1.0    # ä»1.5å‡å°‘åˆ°1.0
  lr: 0.01      # ä»0.025å‡å°‘åˆ°0.01
```

**é—®é¢˜3: æ•°æ®å¤„ç†å¤±è´¥**
```bash
# æ£€æŸ¥æ•°æ®æ ¼å¼
head -5 your_data.csv
# ç¡®ä¿åŒ…å«å¿…è¦åˆ—: material_id, cif, formation_energy_per_atom, target_property

# æ£€æŸ¥æ•°æ®è´¨é‡
python -c "
import pandas as pd
df = pd.read_csv('your_data.csv')
print('Data shape:', df.shape)
print('Missing values:', df.isnull().sum())
print('Columns:', list(df.columns))
"
```

**é—®é¢˜4: GPUå†…å­˜ä¸è¶³**
```bash
# ç›‘æ§GPUä½¿ç”¨
watch -n 1 nvidia-smi

# å‡å°‘æ¨¡å‹å‚æ•°
# åœ¨é…ç½®æ–‡ä»¶ä¸­ä¿®æ”¹:
hidden_dim: 128    # ä»256å‡å°‘åˆ°128
latent_dim: 128    # ä»256å‡å°‘åˆ°128
```

---

### ğŸ“Š æ€§èƒ½ç›‘æ§

#### è®­ç»ƒè¿‡ç¨‹ç›‘æ§
```bash
# æŸ¥çœ‹è®­ç»ƒæ—¥å¿—
tail -f results/your_experiment/training.log

# ç›‘æ§GPUä½¿ç”¨
watch -n 1 nvidia-smi

# æ£€æŸ¥ä»»åŠ¡æƒé‡æ¼”åŒ– (å¦‚æœä½¿ç”¨GradNorm)
python -c "
import torch
import matplotlib.pyplot as plt

# åŠ è½½æ£€æŸ¥ç‚¹
ckpt = torch.load('results/your_experiment/last.ckpt')
if 'gradnorm.task_weights' in ckpt['state_dict']:
    weights = ckpt['state_dict']['gradnorm.task_weights']
    print('Current task weights:', weights)
"
```

#### è¯„ä¼°ç»“æœæ£€æŸ¥
```bash
# æ£€æŸ¥è¯„ä¼°ç»“æœ
cat results/your_experiment/enhanced_evaluation/evaluation_summary.json

# æŸ¥çœ‹å¸•ç´¯æ‰˜å‰æ²¿
ls results/your_experiment/enhanced_evaluation/*/
# åº”è¯¥åŒ…å«: pareto_front.png, pareto_data.csv, detailed_metrics.json
```

---

### ğŸ“ å­¦ä¹ è·¯å¾„å»ºè®®

#### åˆå­¦è€… (ç¬¬1-2å‘¨)
1. è¿è¡Œå¿«é€Ÿç¤ºä¾‹ï¼Œç†è§£åŸºæœ¬æµç¨‹
2. é˜…è¯»ç®—æ³•ä»‹ç»ï¼Œç†è§£æ ¸å¿ƒæ¦‚å¿µ
3. ä½¿ç”¨é¢„å®šä¹‰é…ç½®å¤„ç†è‡ªå·±çš„æ•°æ®
4. è®­ç»ƒç¬¬ä¸€ä¸ªæ¨¡å‹å¹¶æŸ¥çœ‹ç»“æœ

#### è¿›é˜¶ç”¨æˆ· (ç¬¬3-4å‘¨)
1. å¯¹æ¯”ä¸åŒå¤šç›®æ ‡ä¼˜åŒ–æ–¹æ³•
2. å®éªŒGradNorm vs å›ºå®šæƒé‡
3. è°ƒä¼˜è¶…å‚æ•°æå‡æ€§èƒ½
4. åˆ†æå¸•ç´¯æ‰˜å‰æ²¿è´¨é‡

#### é«˜çº§ç”¨æˆ· (ç¬¬5-8å‘¨)
1. æ·±å…¥ç†è§£å„ç®—æ³•åŸç†
2. ä¿®æ”¹æ¨¡å‹æ¶æ„é€‚åº”ç‰¹å®šé—®é¢˜
3. å¼€å‘æ–°çš„è¯„ä¼°æŒ‡æ ‡
4. é›†æˆé¢å¤–çš„ç‰©ç†çº¦æŸ

#### ç ”ç©¶è€… (æŒç»­)
1. å‘è¡¨æ–¹æ³•æ”¹è¿›å’Œåº”ç”¨è®ºæ–‡
2. è´¡çŒ®ä»£ç åˆ°å¼€æºç¤¾åŒº
3. æ‰©å±•åˆ°æ–°çš„ææ–™ä½“ç³»
4. å¼€å‘ä¸‹ä¸€ä»£ç®—æ³•

---

### ğŸ“š æ¨èèµ„æº

#### ç†è®ºå­¦ä¹ 
- **å¤šç›®æ ‡ä¼˜åŒ–**: Miettinen - "Nonlinear Multiobjective Optimization"
- **æ·±åº¦å­¦ä¹ **: Goodfellow - "Deep Learning"
- **å›¾ç¥ç»ç½‘ç»œ**: Hamilton - "Graph Representation Learning"
- **ææ–™ä¿¡æ¯å­¦**: Butler - "Machine learning for molecular and materials science"

#### å®è·µå·¥å…·
- **PyTorch Geometric**: å›¾ç¥ç»ç½‘ç»œæ¡†æ¶
- **Pymatgen**: ææ–™ç§‘å­¦Pythonåº“
- **ASE**: åŸå­æ¨¡æ‹Ÿç¯å¢ƒ
- **VESTA**: æ™¶ä½“ç»“æ„å¯è§†åŒ–

#### æ•°æ®èµ„æº
- **Materials Project**: ææ–™æ•°æ®åº“
- **OQMD**: å¼€æ”¾é‡å­ææ–™æ•°æ®åº“
- **ICSD**: æ— æœºæ™¶ä½“ç»“æ„æ•°æ®åº“
- **COD**: æ™¶ä½“å­¦å¼€æ”¾æ•°æ®åº“

è¿™ä¸ªå¿«é€Ÿå…¥é—¨æŒ‡å—ä¸ºç”¨æˆ·æä¾›äº†ä»å®‰è£…åˆ°é«˜çº§åº”ç”¨çš„å®Œæ•´è·¯å¾„ï¼Œç¡®ä¿èƒ½å¤Ÿå¿«é€Ÿä¸Šæ‰‹å¹¶å……åˆ†åˆ©ç”¨Enhanced CDVAEç³»ç»Ÿçš„å¼ºå¤§åŠŸèƒ½ã€‚