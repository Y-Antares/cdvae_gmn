#!/bin/bash
# Enhanced Data Preparation Usage Examples
# 升级后的预处理程序使用示例

echo "Enhanced Multi-Target Data Preparation Examples"
echo "=============================================="

# 1. 固定训练集大小的示例
echo "1. 固定训练集大小示例:"
echo "===================="

# 示例1: 固定训练集为10000个样本，验证集和测试集按比例缩放
echo "# 固定训练集为10000个样本"
echo "python enhanced_prepare_multi_target_data.py \\"
echo "  --input raw_data/perovskite_data.csv \\"
echo "  --output_dir data/perov_10k \\"
echo "  --target_property band_gap \\"
echo "  --formation_energy_col formation_energy_per_atom \\"
echo "  --train_size 10000 \\"
echo "  --val_ratio 0.1 \\"
echo "  --test_ratio 0.1"
echo ""

# 示例2: 固定训练集为5000个样本，小数据集快速测试
echo "# 固定训练集为5000个样本（快速测试）"
echo "python enhanced_prepare_multi_target_data.py \\"
echo "  --input raw_data/perovskite_data.csv \\"
echo "  --output_dir data/perov_5k_test \\"
echo "  --target_property band_gap \\"
echo "  --train_size 5000 \\"
echo "  --val_ratio 0.15 \\"
echo "  --test_ratio 0.15 \\"
echo "  --stratify_bins 5"
echo ""

# 示例3: 超大训练集
echo "# 超大训练集（50000个样本）"
echo "python enhanced_prepare_multi_target_data.py \\"
echo "  --input raw_data/large_materials_database.csv \\"
echo "  --output_dir data/materials_50k \\"
echo "  --target_property formation_energy \\"
echo "  --train_size 50000 \\"
echo "  --val_ratio 0.05 \\"
echo "  --test_ratio 0.05 \\"
echo "  --stratify_bins 20"
echo ""

# 2. 传统比例分割示例
echo "2. 传统比例分割示例:"
echo "===================="

# 示例4: 标准80/10/10分割
echo "# 标准80/10/10分割"
echo "python enhanced_prepare_multi_target_data.py \\"
echo "  --input raw_data/carbon_allotropes.csv \\"
echo "  --output_dir data/carbon_standard \\"
echo "  --target_property elastic_modulus \\"
echo "  --train_ratio 0.8 \\"
echo "  --val_ratio 0.1 \\"
echo "  --test_ratio 0.1"
echo ""

# 示例5: 不平衡分割（更多训练数据）
echo "# 不平衡分割（90/5/5）"
echo "python enhanced_prepare_multi_target_data.py \\"
echo "  --input raw_data/metal_oxides.csv \\"
echo "  --output_dir data/oxides_90_5_5 \\"
echo "  --target_property conductivity \\"
echo "  --train_ratio 0.9 \\"
echo "  --val_ratio 0.05 \\"
echo "  --test_ratio 0.05"
echo ""

# 3. 高级配置示例
echo "3. 高级配置示例:"
echo "================"

# 示例6: 精细分层采样
echo "# 精细分层采样（20个分层）"
echo "python enhanced_prepare_multi_target_data.py \\"
echo "  --input raw_data/complex_materials.csv \\"
echo "  --output_dir data/complex_fine_stratified \\"
echo "  --target_property thermal_conductivity \\"
echo "  --train_size 15000 \\"
echo "  --stratify_bins 20 \\"
echo "  --random_state 123"
echo ""

# 示例7: 跳过分析和验证（快速处理）
echo "# 快速处理（跳过分析和验证）"
echo "python enhanced_prepare_multi_target_data.py \\"
echo "  --input raw_data/quick_test_data.csv \\"
echo "  --output_dir data/quick_test \\"
echo "  --target_property hardness \\"
echo "  --train_size 1000 \\"
echo "  --no_analysis \\"
echo "  --no_validation"
echo ""

# 4. 实际应用场景示例
echo "4. 实际应用场景示例:"
echo "==================="

# 示例8: 钙钛矿材料优化
echo "# 钙钛矿材料带隙优化"
echo "python enhanced_prepare_multi_target_data.py \\"
echo "  --input raw_data/perovskite_screening.csv \\"
echo "  --output_dir data/perov_bandgap_opt \\"
echo "  --target_property dir_gap \\"
echo "  --formation_energy_col formation_energy_per_atom \\"
echo "  --train_size 12000 \\"
echo "  --val_ratio 0.08 \\"
echo "  --test_ratio 0.12 \\"
echo "  --stratify_bins 15 \\"
echo "  --random_state 42"
echo ""

# 示例9: 碳材料弹性模量预测
echo "# 碳材料弹性模量预测"
echo "python enhanced_prepare_multi_target_data.py \\"
echo "  --input raw_data/carbon_materials_db.csv \\"
echo "  --output_dir data/carbon_elastic \\"
echo "  --target_property bulk_modulus \\"
echo "  --formation_energy_col e_form_per_atom \\"
echo "  --train_size 8000 \\"
echo "  --val_ratio 0.1 \\"
echo "  --test_ratio 0.1 \\"
echo "  --stratify_bins 12"
echo ""

# 示例10: 金属合金热导率研究
echo "# 金属合金热导率研究"
echo "python enhanced_prepare_multi_target_data.py \\"
echo "  --input raw_data/alloy_thermal_properties.csv \\"
echo "  --output_dir data/alloy_thermal \\"
echo "  --target_property thermal_conductivity \\"
echo "  --formation_energy_col formation_enthalpy \\"
echo "  --train_size 6000 \\"
echo "  --val_ratio 0.12 \\"
echo "  --test_ratio 0.13 \\"
echo "  --stratify_bins 10"
echo ""

# 5. 批量处理示例
echo "5. 批量处理示例:"
echo "================"

# 批量处理函数
echo "# 批量处理不同大小的训练集"
echo "process_multiple_sizes() {"
echo "  local input_file=\$1"
echo "  local base_output_dir=\$2"
echo "  local target_prop=\$3"
echo ""
echo "  # 定义不同的训练集大小"
echo "  sizes=(1000 2000 5000 10000 15000)"
echo ""
echo "  for size in \"\${sizes[@]}\"; do"
echo "    output_dir=\"\${base_output_dir}/train_\${size}\""
echo "    echo \"Processing training size: \$size\""
echo ""
echo "    python enhanced_prepare_multi_target_data.py \\"
echo "      --input \"\$input_file\" \\"
echo "      --output_dir \"\$output_dir\" \\"
echo "      --target_property \"\$target_prop\" \\"
echo "      --train_size \"\$size\" \\"
echo "      --val_ratio 0.1 \\"
echo "      --test_ratio 0.1 \\"
echo "      --stratify_bins 10 \\"
echo "      --random_state 42"
echo ""
echo "    if [ \$? -eq 0 ]; then"
echo "      echo \"✅ Successfully processed training size \$size\""
echo "    else"
echo "      echo \"❌ Failed to process training size \$size\""
echo "    fi"
echo "  done"
echo "}"
echo ""

# 使用批量处理函数
echo "# 使用示例:"
echo "process_multiple_sizes raw_data/perovskite_data.csv data/perov_size_study band_gap"
echo ""

# 6. 数据质量检查示例
echo "6. 数据质量检查示例:"
echo "==================="

# 检查生成的数据集
echo "# 检查数据集分割质量"
echo "check_dataset_quality() {"
echo "  local dataset_dir=\$1"
echo ""
echo "  echo \"Checking dataset quality in: \$dataset_dir\""
echo ""
echo "  # 检查文件是否存在"
echo "  for split in train val test; do"
echo "    file=\"\${dataset_dir}/\${split}.csv\""
echo "    if [ -f \"\$file\" ]; then"
echo "      lines=\$(wc -l < \"\$file\")"
echo "      echo \"  \$split.csv: \$((lines-1)) samples\""
echo "    else"
echo "      echo \"  ❌ Missing \$split.csv\""
echo "    fi"
echo "  done"
echo ""
echo "  # 检查元数据"
echo "  if [ -f \"\${dataset_dir}/metadata.json\" ]; then"
echo "    echo \"  ✅ Metadata available\""
echo "  else"
echo "    echo \"  ❌ Missing metadata.json\""
echo "  fi"
echo ""
echo "  # 检查分析结果"
echo "  if [ -d \"\${dataset_dir}/distribution_analysis\" ]; then"
echo "    echo \"  ✅ Distribution analysis available\""
echo "  fi"
echo ""
echo "  if [ -d \"\${dataset_dir}/split_validation\" ]; then"
echo "    echo \"  ✅ Split validation available\""
echo "  fi"
echo "}"
echo ""

# 7. 实际运行示例
echo "7. 实际运行示例:"
echo "================"

echo "# 示例：处理钙钛矿数据集"
echo "# 假设我们有一个包含以下列的CSV文件："
echo "# - material_id: 材料ID"
echo "# - cif: 晶体结构"
echo "# - formation_energy_per_atom: 形成能"
echo "# - dir_gap: 直接带隙"
echo ""
echo "python enhanced_prepare_multi_target_data.py \\"
echo "  --input /path/to/perovskite_database.csv \\"
echo "  --output_dir ./data/perov_optimized \\"
echo "  --target_property dir_gap \\"
echo "  --formation_energy_col formation_energy_per_atom \\"
echo "  --train_size 10000 \\"
echo "  --val_ratio 0.1 \\"
echo "  --test_ratio 0.1 \\"
echo "  --stratify_bins 15 \\"
echo "  --random_state 42"
echo ""

echo "# 检查结果"
echo "check_dataset_quality ./data/perov_optimized"
echo ""

# 8. 常见问题和解决方案
echo "8. 常见问题和解决方案:"
echo "======================"

echo "# 问题1: 训练集大小超过总数据量"
echo "# 解决方案: 程序会自动检测并报错，请调整train_size"
echo ""

echo "# 问题2: 数据分布不均匀"
echo "# 解决方案: 增加stratify_bins数量"
echo "python enhanced_prepare_multi_target_data.py \\"
echo "  --input data.csv \\"
echo "  --output_dir output \\"
echo "  --target_property target \\"
echo "  --train_size 5000 \\"
echo "  --stratify_bins 20  # 增加分层数量"
echo ""

echo "# 问题3: 验证集和测试集太小"
echo "# 解决方案: 增加val_ratio和test_ratio"
echo "python enhanced_prepare_multi_target_data.py \\"
echo "  --input data.csv \\"
echo "  --output_dir output \\"
echo "  --target_property target \\"
echo "  --train_size 5000 \\"
echo "  --val_ratio 0.15 \\"
echo "  --test_ratio 0.15"
echo ""

# 9. 输出文件说明
echo "9. 输出文件说明:"
echo "================"

echo "处理完成后，输出目录将包含以下文件："
echo ""
echo "├── train.csv                           # 训练集数据"
echo "├── val.csv                            # 验证集数据"  
echo "├── test.csv                           # 测试集数据"
echo "├── metadata.json                      # 数据集元信息"
echo "├── distribution_analysis/             # 数据分布分析"
echo "│   ├── dataset_target_distribution.png"
echo "│   └── dataset_energy_vs_target.png"
echo "└── split_validation/                  # 数据分割验证"
echo "    ├── dataset_split_comparison.png"
echo "    ├── dataset_split_statistics.csv"
echo "    └── dataset_ks_test_results.json"
echo ""

echo "=============================================="
echo "注意事项:"
echo "1. 确保输入CSV文件包含必要的列：material_id, cif, formation_energy, target_property"
echo "2. 使用固定的random_state确保结果可复现"
echo "3. 根据数据集大小调整stratify_bins参数"
echo "4. 检查生成的分析图表以验证数据质量"
echo "5. KS测试p值>0.05表示数据分割具有良好的均匀性"